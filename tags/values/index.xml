<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>values on</title><link>https://mwalton.me/tags/values/</link><description>Recent content in values on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 24 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://mwalton.me/tags/values/index.xml" rel="self" type="application/rss+xml"/><item><title>The Values Encoded in Machine Learning Research</title><link>https://mwalton.me/notes/ml-value-encoding/</link><pubDate>Fri, 24 Mar 2023 00:00:00 +0000</pubDate><guid>https://mwalton.me/notes/ml-value-encoding/</guid><description>paper
calls into question vague definitions of ML as value-neutral annotation of papers to reveal &amp;ldquo;values&amp;rdquo;: justification for choice of project which attributes of project uplift / advertised consideration of potential negative consequences institutional affiliation &amp;amp; funding societal need: 15%, discuss negative potential: 1% 59 values codified most common: performance, generalization, quantitative evidence, efficiency, building on past work, novelty textual evidence demonstrating values reflect assumptions &amp;amp; implication supporting centralization of power contributions open source annotation scheme for studying values in documents apply to 100 influential ML papers textual analysis to understand operationalization of values quantitative analysis of affiliations &amp;amp; funding of influential papers justificatory chain: chain of reasoning for technical / societal need to motivate contribution !</description></item><item><title>Rebuilding Society on Meaning</title><link>https://mwalton.me/notes/meaning/</link><pubDate>Thu, 16 Mar 2023 00:00:00 +0000</pubDate><guid>https://mwalton.me/notes/meaning/</guid><description>Rebuilding Society on Meaning
Ideas an interesting modeling approach could be combining an LM that converses with users encouraging them to introspect on their values combined w/ a theory of mind that the model constructs (and persists) of them between use sessions (this could also get quite dark) i like the idea of trying to align recommenders w/ what users actually value, however I&amp;rsquo;m concerned about how the existing incentive structure (advertising / attention economy / surveillance capitalism) will incorporate research in this area.</description></item></channel></rss>