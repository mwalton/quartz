<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLMs on</title><link>https://mwalton.me/tags/LLMs/</link><description>Recent content in LLMs on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 06 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://mwalton.me/tags/LLMs/index.xml" rel="self" type="application/rss+xml"/><item><title>LLMs, Innovation, and Capitalism</title><link>https://mwalton.me/notes/llms-innovation-capitalism/</link><pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><guid>https://mwalton.me/notes/llms-innovation-capitalism/</guid><description> LLMs, Innovation, and Capitalism
increased corporate gatekeeping motivated by capital, not &amp;ldquo;ai safety&amp;rdquo; advocates for open science; closed models shape &amp;amp; constrain what ai gets built and whose interests considered closed model is on the take from open source research main barriers to large model research: economic / resource constraints lack of access to models themselves closed models incentivizes / necessitates duplication of effort (eg open reproductions or corporate peers building their own closed competing models) risk and ethics only considered to the extent that they protect profits (minimizing &amp;ldquo;reputational risk&amp;rdquo;) highlights ethical considerations around LLM privileging english speakers, exploitative labor practices &amp;amp; environmental costs community can discourage closed development through a reproducibility requirement</description></item><item><title>Stochastic Parrots Day ðŸ¦œ (DAIR)</title><link>https://mwalton.me/notes/dair-stochastic-parrots/</link><pubDate>Sun, 19 Mar 2023 00:00:00 +0000</pubDate><guid>https://mwalton.me/notes/dair-stochastic-parrots/</guid><description>![[notes/images/stochastic-parrots.png]]
Retrospective Problem: presented as knowledge access systems; similar to issue w/ meta galactica for science Language: pairs of form and meaning, language models only have access to form Good at generating plausible sounding text; refined w/ preferences at producing non-offensive plausible sounding text Philosophers asking: â€œare the models thinking?</description></item></channel></rss>