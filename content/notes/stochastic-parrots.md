---
title: "Stochastic Parrots Day ğŸ¦œ"
date: 2023-03-19
---
![[notes/images/stochastic-parrots.png]]

# Retrospective
- Problem: presented as knowledge access systems; similar to issue w/ [meta galactica](https://www.technologyreview.com/2022/11/18/1063487/meta-large-language-model-ai-only-survived-three-days-gpt-3-science/) for science
- Language: pairs of form and meaning, language models only have access to form
- Good at generating plausible sounding text; refined w/ preferences at producing non-offensive plausible sounding text
- Philosophers asking: â€œare the models thinking?â€ etc. we donâ€™t want conversation to go there
- Harms and risks of language models to present humans; citation did not exist
- Garden path sentences: â€œThe horse raced past the barn fellâ€ metaphor for larger and larger language models; misdirection of research effort
- Language had a similar explosion to vision where it suddenly can solve large problems; â€œwait, we havenâ€™t considered all the harms yet!â€
- Bad idea from POV of information literacy
- [Situating search](https://dl.acm.org/doi/fullHtml/10.1145/3498366.3505816) Emily bender
- Problem with LLMS is w/ how their marketed, used & built
# Worker exploitation, data theft & centralization of power
- Content moderation data labor (Kenyan data work)
	- Companies deliberately hire most vulnerable; prevents workers from speaking out
	- Moderation is a mental health concern
- Milagros Miceli
	- Ultimately, QA abides by what client wants
	- Gig work is common; payment per task
	- Data work & content moderation outsourced
- Safiya Umoja Noble
	- â€œConversations like this are how we become better advocates for each otherâ€
	- We should be skeptical & careful
	- **Researchers should be taking a page out of climate scientists books: â€œwish they had become activists, rather than just doing the research and handing it off to policy makersâ€**
# AI Hype vs reality
- Education (Belize Mont-Louis)
	- How to use technology intentionally so students benefit and are not harmed
	- Blocking or buying detector products not the right strategy, solution is better teaching
	- Designing educational strategies that evaluate students on factors LLMs
	- Rethink education that requires students to produce things that helps them learn what they need to
	- Improving public understanding of bias and limitations
- Startups (Asmelash Teka)
	- GPT sucking up all the air in the room
- Combatting hype (Mark Riedi)
	- tradeoff between precise vs understandable language / metaphor
	- LLMS as â€œbackward lookingâ€ being applied to â€œforward lookingâ€ problems
- Productivity improvement
	- Utopian claims of AI companies
	- Counter to the incentive structure of capitalism: Automating a task is not rewarded with additional leisure time; labor structure just shifts
	- Shifting labor from creation to editing & oversight requires vigilance (humans are bad at this)
- Education gaps for marginalized students
	- Who is the creator vs consumer of the technology?
	- Technology can often close gaps (increases access)
	- Mark: AI tech people have a choice in which area they want to disrupt. Often pick on teachers as inefficient or replaceable. The real problem is not how scale up / disrupt, itâ€™s a resource allocation problem.
	- Teaching is not about information transfer, its about relationships and social development
- Mark: nsf grant, promise first year we will write no code and just spend time interviewing and understanding teachersâ€™ needs and use cases
- **Refreshing to hear that the first step for an AI researcher is to get to know and understand the stakeholders the tool is for / going to affect**
- Mark: **â€œYou can do good science without writing codeâ€**
- How to cut through the hype?
	- Stay focused on the things you care about
	- Use tools yourself. Try to break them. Figuring out what they canâ€™t do identifies its boundaries & limitations
	- Counterpoint: every time you break and find a boundary, it provides the organization additional training data to extend the boundaries
	- Keep in mind what is being published as news may be marketing
	- Develop a strategy to identify good skeptical news outlets and journalists
- Mark: last 4 months playing amateur sleuth â€œglass onion GPT editionâ€ (relatable ğŸ˜‚ğŸ˜…)
# Whatâ€™s next? A call to action
- EU AI act (sarah andrew)
	- Small piece of legislation initially built under the assumption â€œAIâ€ was just a new piece of tech; academics and NGOs jumped in and (successfully) expanded protections
	- Human rights protections built into creation and use
	- Use case specific legislation didnâ€™t cover general purpose AI
- Global south context (Nanjala Nyabola)
	- Gap in capacity to develop AI strategy & policy
	- Need international community to set baseline of conduct for disadvantaged nation states to protect themselves
	- Most elaborate misinformation campaigns run in disadvantaged nations (often by the state)
	- Unequal partnerships w/Â  lead to exploitative relationships
	- **â€œConsequences of developing this technology will not be constrained by bordersâ€**
- Legal frameworks for Art and ownership (Steven Zapata)
	- Class action lawsuits against AI companies scoping what the problems are
	- Copyright infringement, fair use
- Can the system be reimagined w/o exploitation?
	- Incentive distorting problems: 1. We exist to consume 2. Accumulation is good
	- The term â€œethicalâ€ is slippery and nonspecific
	- **Ground the definition in human rights**
- Amplify the stories of the harms occuring now. policy makers tend to fall into the thinking that AI conversations are only about the future
- Demystify the rulemaking process (call for journalists and tech blogs) make sure information travels
- Break down academic silos; have conversations and build diverse transdisciplinary coalitions.
- **Purpose is not to win, the purpose to transform**
- Need to educate representatives
- â€œYou put out gpt4 and release it into the world, whatever bad things its capable of, its already capable ofâ€ red team examples:
	- Demonstrate its capacity to deceive a human on task rabbit to solve captchas
	- How can i make a deadly chemical with household ingredients?
	- Thatâ€™s just what they decided to test; and then put guardrails in place to prevent those specific behaviors
- Willful ignorance of tech industry
- â€œWeâ€™re either all going to make it, or none of us are going to make itâ€
- Ask yourself: does the work that youâ€™re doing help or harm?