{"/":{"title":"M. Walton","content":"\nWelcome traveler! You've stumbled into my humble [[thoughts/digital-garden |garden of ideas]]!\n\n\u003e *The idea is like grass. It craves light, likes crowds, thrives on crossbreeding, grows better for being stepped on.* ‚ÄîUrsula K. Le Guin\n\nI'm a researcher (primarily focused on multi-agent reinforcement learning) currently experimenting with improving [[thoughts/participatory-design|public participation]] in the design \u0026 [[thoughts/alignment|alignment]] of artificial intelligence and the emerging potential of human [[thoughts/ci |collective intelligence]].\n\nLately I've been trying to be more intentional about my research strategies as our species evolves towards a communal [[thoughts/stewardship |stewardship]] model of technological progress. Here are some paths you might follow to get to know me, my research and interests:\n\n- [[cv/doings|üå± greenhouse]]: current doings, musings and evolving ideas.\n- [[cv/projects|üå≤ arboretum]]: projects that I'm happy to say took root.\n- [[books/_booklist|üçÉ tea garden]]: curated reading list. grab some üçµ and enjoy!","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/books/_booklist":{"title":"Booklist","content":"# Currently Reading\n- [Curius](https://curius.app/myke-walton)\n- [Paperpile](https://paperpile.com/shared/eYZgFI)\n\n# Recent Reads\n- [Emergent Strategy](https://www.akpress.org/emergentstrategy.html), Adrienne Maree Brown\n- [Lightly on the Land](https://www.mountaineers.org/books/books/lightly-on-the-land-the-sca-trail-building-and-maintenance-manual-2nd-edition), Student Conservation Association\n- [Animal Architects](https://www.publishersweekly.com/978-0-465-02782-8), Carol Grant Gould \u0026 James L. Gould\n- [The Dispossessed](https://www.ursulakleguin.com/dispossessed), Ursula K. Le Guin\n\n# Favorites of 2022\n- [Braiding Sweetgrass](https://milkweed.org/book/braiding-sweetgrass), Robin Wall Kimerer\n- [Designs for the Pluriverse](https://www.dukeupress.edu/designs-for-the-pluriverse), Arturo Escobar\n- [Megaloceros and Magic](https://www.authorhouse.com/en/bookstore/bookdetails/847822-megaloceros-and-magic), June Dickson (my cousin's book üéâ)\n- [Parable of the Sower](https://www.octaviabutler.com/parableseries), Octavia E. Butler\n\n# üêê GOATs\n\nBooks, papers \u0026 projects that fundamentally shaped my thinking or made me radically reconsider something I thought I understood fairly well\n- [Designs for the Pluriverse](https://www.dukeupress.edu/designs-for-the-pluriverse)\n- [Reinforcement Learning: An Introduction](http://www.incompleteideas.net/book/the-book-2nd.html)\n- [A Unified Game-Theoretic Approach to Multiagent RL](https://proceedings.neurips.cc/paper/2017/hash/3323fe11e9595c09af38fe67567a9394-Abstract.html)\n- [On the Dangers of Stochastic Parrots ü¶ú](https://dl.acm.org/doi/10.1145/3442188.3445922)\n\n# Top of the reading pile\n- [Seeing Like a State](https://yalebooks.yale.edu/book/9780300078152/seeing-like-a-state/), James C. Scott\n\n# Á©ç„ÇìË™≠ Antilibrary\nBehold, my [antilibrary](https://nesslabs.com/antilibrary):\n- [Goodreads](https://www.goodreads.com/review/list/127050485-michael-walton?shelf=to-read)\n- [Paperpile](https://paperpile.com/shared/nBQ95P)","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/books/animal-architects":{"title":"Animal Architects","content":"","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/books/braiding-sweetgrass":{"title":"Braiding Sweetgrass","content":"","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/books/dispossessed":{"title":"The Dispossessed","content":"","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/books/emergent-strategy":{"title":"Emergent Strategy","content":"\n[Emergent Strategy](https://www.akpress.org/emergentstrategy.html), Adrienne Maree Brown","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/books/parable-of-the-sower":{"title":"Parable of the Sower","content":"","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/books/pluriverse":{"title":"Designs for the Pluriverse","content":"","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/cv/doings":{"title":"Current Doings","content":"# Research\n- [Autopoiesis](https://autopoiesis.substack.com/): Playful musings on the study and [[thoughts/stewardship|stewardship]] of intelligent systems: artificial, natural, collective \u0026 complex.\n\n- Scaling [[thoughts/participatory-design|Participatory]] Artificial Intelligence\n\n- The [[thoughts/alignment|Alignment of Alignment]]\n\n# Volunteering\n- **[Good Foundation Forming](https://www.goodfoundationforming.org/)**: mentorship and career counseling for Mongolian high-school \u0026 early university students interested in STEM\n- [Educational Equality Institute](https://theeducationalequalityinstitute.org/): grant research and writing for Oslo-based nonprofit fighting educational inequality\n- **[Washington Trails Association](https://www.wta.org/)**: maintenance on Washington state trails and outdoor public spaces","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/cv/ideas":{"title":"Random Ideas","content":"The compost heap of random scraps of ideas I've been thinking about. Some are new, some are  old; some are being actively thought about, others have been digesting for a long time. If you are actively working on research that sounds related and are interested in a discussion or possible collaboration, please get in touch!\n\n# Research\n- Democratic Reinforcement Learning:\n\t- liquid democracy game: delegation game; players have different private info, benefits each other in aggregate to delegate authority when other player has requisite private info\n\t- Comparative experiments using different voting schemes in MARL (quadratic etc.)\n- theory of mind for language models\n- narrative priors\n- crowdfunded foundation models\n# AI Institutional Design Experiments\n- Participatory AI Unconference\n\t- **Objective**: experiments in democratic participatory design. All stages of the design process incorporate participation of diversity of stakeholders\n\t- **Methods**: Short talks + poster session idea jam, deliberative discourse sessions, proposal construction, election \u0026 sub-teaming, hackathon\n\t- **Deliverable(s)**: Publication + code for projects created + event metastudy incorporating participant survey, lessons learned, case study results\n# Applications\n(please feel free to steal; credit for inspiration is cool, collaboration is awesome. but ultimately I'd rather just see them be built and my time and attention is woefully finite ü•≤)\n- moodring: community care mental health support\n- MARL microgrids \u0026 meshnetworks\n- Infinite forest: immersive generated VR forest\n- **scrutinize.me**: The Contrarian Research Tool üòà üéì User begins with a claim, articles supporting \u0026 against. A language model plays ‚Äúdevils advocate‚Äù. argument lists w/ evidence articles supporting \u0026 against in two columns below. User updates a ‚Äúconfidence‚Äù slider to illustrate dunning-kruger effect. Inspired by: [Learning By Writing](https://www.cold-takes.com/learning-by-writing/)\n\t- ‚Äúlike a GAN for your hypotheses‚Äù - ai nerd\n\t- ‚Äúi hate it‚Äù - prominent american politician\n\t- ‚Äústop stealing my dopamine‚Äù - terminally online debate bro\n- digital mutual aid tools\n\t- virtual community fridge\n\t- toolshare / skillshare / laborshare tools and platforms","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/cv/projects":{"title":"Projects","content":"This is a list of notable projects and publications I've worked on. Find me on [github](https://github.com/mwalton) or [scholar](https://scholar.google.com/citations?user=TTEHCqUAAAAJ) for more!\n\n- [[cv/pubs/rl-openspiel|Multi-agent Reinforcement Learning in OpenSpiel]]: [paper](https://scholar.google.com/citations?view_op=view_citation\u0026hl=en\u0026user=TTEHCqUAAAAJ\u0026citation_for_view=TTEHCqUAAAAJ:_FxGoFyzp5QC), [code](https://github.com/aicenter/openspiel_reproductions)\n- [[cv/pubs/tom-rl|Theory of Mind for Deep Reinforcement Learning in Hanabi]]: [paper](https://arxiv.org/abs/2101.09328), [code](https://github.com/mwalton/ToM-hanabi-neurips19)\n- [[cv/pubs/dac-rl|Distributed Consensus Reinforcement Learning]]: [patent](https://patents.google.com/patent/US11321635B2/en)\n- [[cv/pubs/intent-anom|Intention-based Behavioral Anomaly Detection]]: [paper](https://xuxie1031.github.io/resources/aaaiw19hung.pdf)\n- [[cv/pubs/mdn-anom|Unsupervised Anomaly Detection for Digital Radio Frequency Transmissions]]: [paper](https://ieeexplore.ieee.org/abstract/document/8260738)\n- [[cv/pubs/mlo|Hunting for Naval Mines with Deep Neural Networks]]: [paper](https://ieeexplore.ieee.org/abstract/document/8232216)","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/cv/pubs/dac-rl":{"title":"Distributed Consensus Reinforcement Learning","content":"Michael Walton, Benjamin Migliori, John Reeder\n![[cv/pubs/images/dac.png]]\nA system is provided for performing a predetermined function within a total area of operation, wherein the system includes a plurality of autonomous agents. Each autonomous agent is able to detect respective local parameters. Each autonomous agent uses a Kalman filter component to establish an environment state based a plurality of state measurements over time. The output of the Kalman filter component within a respective agent is applied to reinforcement learning by an actor-critic task controller, within the respective agent, to determine a subsequent action to be performed by the respective agent in accordance with a reward function. Each agent includes a Kalman consensus filter that addresses errors of the plurality of state measurements over time.\n# Publications\n- [Method for performing multi-agent reinforcement learning in the presence of unreliable communications via distributed consensus](https://patents.google.com/patent/US11321635B2/en) ","lastmodified":"2023-03-19T09:52:53.708370276Z","tags":null},"/cv/pubs/intent-anom":{"title":"Intention-based Behavioral Anomaly Detection","content":"Fan Hung, Xu Xie, Andrew Fuchs, **Michael Walton**, Siyuan Qi, Yixin Zhu, Doug Lange, Song-Chun Zhu\n![[cv/pubs/images/intent-anom.png]]\nIn this work we consider the problem of detecting anomalous deviations from expected behavioral trajectories generated by a multi-agent system. Common methods for time series anomaly detection do not explicitly consider the goal-directed nature of rational agents. This work proposes a method for detection of anomalous behaviors based on agent intent formulated using agent-based Lagrangian Mechanics. We propose an anomaly detection method that simultaneously learns to 1) predict the intended goals of agents from their trajectories, and 2) detect anomalies based on the predictions. The method uses a structured one-class support vector machine (structured OC-SVM), where latent variables represent the intentions (goals) of agents, and SVM weights represent the attraction or repulsion strength of potential goals and obstructions. Model parameters are learned in an unsupervised way. We conduct experiments in a marine surveillance setting, where we monitor high-traffic ports and detect anomalous vessels. Experimental results show that our algorithm shows promise for detecting anomalous behaviors in systems of goal-directed agents.\n\n[paper](https://xuxie1031.github.io/resources/aaaiw19hung.pdf)","lastmodified":"2023-03-19T09:52:53.720371187Z","tags":null},"/cv/pubs/mdn-anom":{"title":"Unsupervised anomaly detection for digital radio frequency transmissions","content":"Michael Walton, Maurice Ayache, Logan Straatemeier, Daniel Gebhardt, Benjamin Migliori\n![[cv/pubs/images/rf.png]]\n\nWe present a novel method of unsupervised anomaly detection using long-short-term memory mixture density networks (LSTM-MDN), applied to timeseries data of digital radio transmissions. The modern radio frequency (RF) environment is a dynamic and ever-changing complex milieu of signals, environmental effects, unintentional interference, and intentional jamming. A consequence of this complex mix is that RF receivers must become better and better at rejecting anomalous signals in order to recover the transmitted information. However, it is not always possible to know a priori what constitutes a valid signal and what constitutes an anomaly (intentional or otherwise), especially with the adoption of cognitive radio techniques. We show that an LSTM-MDN model is able to rapidly learn the training set and produce probability distribution functions for the expected signal as a function of time. We then demonstrate that the negative log likelihood of an incoming test transmission, conditioned on the training set, provides a metric that allows anomalous signals to be detected and labeled. We demonstrate this method for eight popular modulations and for three different anomaly types. By applying unsupervised learning in the temporal domain, we report a fully-generalizable anomaly detection method that may be applied to signals for which the transmission parameters may be unknown or obscured.","lastmodified":"2023-03-19T09:52:53.720371187Z","tags":null},"/cv/pubs/mlo":{"title":"# Hunting for naval mines with deep neural networks","content":"Daniel Gebhardt, Keyur Parikh, Iryna Dzieciuch, Michael Walton, Nhut Anh Vo Hoang\n\n![[cv/pubs/images/mlo.png]]\n\nExplosive naval mines pose a threat to ocean and sea faring vessels, both military and civilian. This work applies deep neural network (DNN) methods to the problem of detecting minelike objects (MLO) on the seafloor in side-scan sonar imagery. We explored how the DNN depth, memory requirements, calculation requirements, and training data distribution affect detection efficacy. A visualization technique (class activation map) was incorporated that aids a user in interpreting the model's behavior. We found that modest DNN model sizes yielded better accuracy (98%) than very simple DNN models (93%) and a support vector machine (78%). The largest DNN models achieved \u003c;1% efficacy increase at a cost of a 17x increase of trainable parameter count and computation requirements. In contrast to DNNs popularized for many-class image recognition tasks, the models for this task require far fewer computational resources (0.3% of parameters), and are suitable for embedded use within an autonomous unmanned underwater vehicle.","lastmodified":"2023-03-19T09:52:53.720371187Z","tags":null},"/cv/pubs/rl-openspiel":{"title":"Multi-agent Reinforcement Learning in OpenSpiel: A Reproduction Report","content":"[paper](https://scholar.google.com/citations?view_op=view_citation\u0026hl=en\u0026user=TTEHCqUAAAAJ\u0026citation_for_view=TTEHCqUAAAAJ:_FxGoFyzp5QC), [code](https://github.com/aicenter/openspiel_reproductions)\n\nMichael Walton, Viliam Lisy\n![[cv/pubs/images/rcfr_horz.png]]\nIn this report, we present results reproductions for several core algorithms implemented in the OpenSpiel framework for learning in games. The primary contribution of this work is a validation of OpenSpiel's re-implemented search and Reinforcement Learning algorithms against the results reported in their respective originating works. Additionally, we provide complete documentation of hyperparameters and source code required to reproduce these experiments easily and exactly.","lastmodified":"2023-03-19T09:52:53.720371187Z","tags":null},"/cv/pubs/tom-rl":{"title":"Theory of Mind for Deep Reinforcement Learning in Hanabi","content":"Andrew Fuchs, **Michael Walton**, Theresa Chadwick, Doug Lange\n![[cv/pubs/images/hanabi_horz.png]]\nThe partially observable card game Hanabi has recently been proposed as a new AI challenge problem due to its dependence on implicit communication conventions and apparent necessity of theory of mind reasoning for efficient play. In this work, we propose a mechanism for imbuing Reinforcement Learning agents with a theory of mind to discover efficient cooperative strategies in Hanabi. The primary contributions of this work are threefold: First, a formal definition of a computationally tractable mechanism for computing hand probabilities in Hanabi. Second, an extension to conventional Deep Reinforcement Learning that introduces reasoning over finitely nested theory of mind belief hierarchies. Finally, an intrinsic reward mechanism enabled by theory of mind that incentivizes agents to share strategically relevant private knowledge with their teammates. We demonstrate the utility of our algorithm against Rainbow, a state-of-the-art Reinforcement Learning agent.\n\n[paper](https://arxiv.org/abs/2101.09328), [code](https://github.com/mwalton/ToM-hanabi-neurips19)","lastmodified":"2023-03-19T09:52:53.720371187Z","tags":null},"/cv/vision":{"title":"Vision","content":"Vibrant, thriving machine learning research and applications ecosystems where diverse pluralities of stakeholders collectively co-design, plan, build and share artificial intelligence tools that align with their values and sustainably meet humanity's needs.\n\n# Principes \nWhile on sabbatical I wrote a lot of rants and manifestos (none of which I'd ever dream of publishing). I had plenty of critiques of the direction of the Artificial Intelligence‚Ñ¢ industry, but it began to become clear just how directionless my own thinking had become. I knew what I was opposed to, but what was I *for*? Among other helpful voices, Kim Crayton's  [Guiding Principles](https://www.kimcrayton.com/guiding-principles/) offered a proactive toehold out of my terminal doomerism:\n\u003e 1. Tech is not neutral, nor is it apolitical\n\u003e 2. Intention without strategy is chaos\n\u003e 3. Lack of inclusion is a risk / crisis management issue\n\u003e 4. Prioritize the most vulnerable\n\n# Values\nFrom this foundation, I decided to roll my own list of values and associated principles to put them into action. I think of these as a both a decision aid and a sort of long-form promise to myself:\n\n1. __Inclusivity__: Genuinely responsible AI requires intentional collaboration and participation across communities with diverse perspectives, backgrounds and experience.\n\n2. __Egalitarianism__: Extreme concentrations of wealth, data and power¬†undermine comprehensive alignment of AI with the values of the communities it impacts. Ensuring safe scaling of next generation AI systems necessitates proactive public engagement and democratic innovation.\n\n3. __Dignity__: Researchers must work in solidarity with and prioritize the concerns of vulnerable parties directly impacted by the technologies we study to ensure the research questions we pose, data we utilize, and models we release into the world minimize exploitation and mitigate societal harm.\n\n4. __Transparency__: Constantly strive to improve communication of results, research activities, strategic planning and decision making processes through open access publication, open source software and data sharing.\n\n5. __Empowerment__: Foster virtual and physical spaces for collaborative knowledge sharing and discourse to empower individuals and communities to use emerging AI tools and actively participate in setting the course our technology pursues.","lastmodified":"2023-03-19T09:52:53.720371187Z","tags":null},"/notes/innovation-gov":{"title":"Anticipatory Innovation Governance","content":"\n","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/notes/meaning":{"title":"Meaning","content":"[Rebuilding Society on Meaning](https://www.rebuildingmeaning.org/)\n# Ideas\n- an interesting modeling approach could be combining an LM that converses with users encouraging them to introspect on their values combined w/ a theory of mind that the model constructs (and persists) of them between use sessions (this could also get quite dark)\n- i like the idea of trying to align recommenders w/ what users actually value, *however* I'm concerned about how the existing incentive structure (advertising / attention economy / surveillance capitalism) will incorporate research in this area. For instance: one solution could involve: gather more data to discern more intimate information about users; which requires additional surveillance and could further drive nefarious attempts to *manipulate* values (ala how maximizing ad revenue leads to feedback loops that manipulate preferences)\n- i‚Äôm intrigued by the idea of inferring an agent‚Äôs values via their attentional policy, and was inspired to some ideas about how this could be accomplished. i am, however, a bit concerned how this might be developed \u0026 deployed given our current incentive structure. as @joe describes, the profit model at present drives engagement via a shallow understanding of the user as consumer. given this paradigm, it would seem that attempting to infer a latent value system would require more complex modeling of the user and thus additional data. though well intentioned, might attempting to infer values under a profit motive incentivize deeper invasions of user‚Äôs privacy and commoditization of their data?\n\n# Notes\n[To those in Humane tech, Machine Learning and Economics: 3 subfields to start](https://rebuildingmeaning.substack.com/p/lets-convene-researchers-and-makers)\n- unified 'humane tech': great list of related orgs, many of whom I've been tracking / reaching out to as well\n- *people develop the virtues needed for the environments and relationships they find themselves in. So, what we want is not a set of virtues. It‚Äôs an algorithm: a way for a person or agent to recognize, conceptualize, and start living by a virtue that‚Äôs missing or needed in their environment*\n- *First up are alternatives to rational choice theory / expected value (I hear it‚Äôs in the works). From there, we probably need to replace game theory wholesale, and there‚Äôll be other serious changes across microeconomics (watch out price theory, information econ, and organizational econ)*\n[Values, Preferences \u0026 Meaningful Choice](https://github.com/jxe/vpm/blob/master/vpm.pdf)\n- central argument: what an agent chooses to attend to in order to make a choice leading up to making a choice (their attentional policy) reveals more about their values than the choice itself (the revealed preference)\n- revealed preferences: simple, universally applicable, robust, and high resolution\n- users can be lead astray / choose something w/o serving their interests when only tracking revealed preferences / engagement metrics\n- non-introspective agents can still (often) express a preference\n- constitutive attentional policies fall short in that they:\n\t- require more introspection\n\t- require more articulacy\n\t- are harder to verify\n- Suggested research directions:\n\t- rich, interactive experiences to uncover CAPs\n\t- infer CAPs from data\n\t- visualizations \u0026 crypotography to make CAPs understandable, auditable and legitimate\n\t\n[The Gradient: Joe Edelman on Meaning-Aligned AI](https://open.substack.com/pub/thegradientpub/p/joe-edelman-meaning-aligned-ai?r=1u24h5\u0026utm_campaign=post\u0026utm_medium=web)\n- revealed preferences assumed independent variables. are dependent variables due induced feedback loop\n\t- feedback loops induced due to recommender providing a small, biased sample to select from\n\t- [values as constitutive attentional policies](https://github.com/jxe/vpm/blob/master/vpm.pdf)\n\t- [Social Programming Considered as a Habitat for Groups](https://nxhx.org/pdf/edelman-habitat.pdf)","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/notes/microsolidarity":{"title":"Microsolidarity","content":"**[Microsolidarity](https://www.microsolidarity.cc/)**: community-building approach emphasizing meaning \u0026 belonging; highlights strives to identify scale-invariant / self-similar features of organizations. written by Loomio (democratic decision making tool for online communities) co-founder.","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/notes/showcase":{"title":"Showcase","content":"\nWant to see what Quartz can do? Here are some cool community gardens :)\n\n- [Quartz Documentation (this site!)](https://quartz.jzhao.xyz/)\n- [Jacky Zhao's Garden](https://jzhao.xyz/)\n- [Scaling Synthesis - A hypertext research notebook](https://scalingsynthesis.com/)\n- [AWAGMI Intern Notes](https://notes.awagmi.xyz/)\n- [Shihyu's PKM](https://shihyuho.github.io/pkm/)\n- [SlRvb's Site](https://slrvb.github.io/Site/)\n- [Course notes for Information Technology Advanced Theory](https://a2itnotes.github.io/quartz/)\n- [Brandon Boswell's Garden](https://brandonkboswell.com)\n- [Siyang's Courtyard](https://siyangsun.github.io/courtyard/)\n- [Data Dictionary üß†](https://glossary.airbyte.com/)\n- [sspaeti.com's Second Brain](https://brain.sspaeti.com/)\n- [oldwinter„ÅÆÊï∞Â≠óËä±Âõ≠](https://garden.oldwinter.top/)\n- [SethMB Work](https://sethmb.xyz/)\n- [Abhijeet's Math Wiki](https://abhmul.github.io/quartz/Math-Wiki/)\n- [Mike's AI Garden ü§ñ ü™¥ ](https://mwalton.me/)\n\nIf you want to see your own on here, submit a [Pull Request adding yourself to this file](https://github.com/jackyzha0/quartz/blob/hugo/content/notes/showcase.md)!\n","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/notes/stochastic-parrots":{"title":"Stochastic Parrots Day ü¶ú","content":"![[notes/images/stochastic-parrots.png]]\n\n# Retrospective\n- Problem: presented as knowledge access systems; similar to issue w/ [meta galactica](https://www.technologyreview.com/2022/11/18/1063487/meta-large-language-model-ai-only-survived-three-days-gpt-3-science/) for science\n- Language: pairs of form and meaning, language models only have access to form\n- Good at generating plausible sounding text; refined w/ preferences at producing non-offensive plausible sounding text\n- Philosophers asking: ‚Äúare the models thinking?‚Äù etc. we don‚Äôt want conversation to go there\n- Harms and risks of language models to present humans; citation did not exist\n- Garden path sentences: ‚ÄúThe horse raced past the barn fell‚Äù metaphor for larger and larger language models; misdirection of research effort\n- Language had a similar explosion to vision where it suddenly can solve large problems; ‚Äúwait, we haven‚Äôt considered all the harms yet!‚Äù\n- Bad idea from POV of information literacy\n- [Situating search](https://dl.acm.org/doi/fullHtml/10.1145/3498366.3505816) Emily bender\n- Problem with LLMS is w/ how their marketed, used \u0026 built\n# Worker exploitation, data theft \u0026 centralization of power\n- Content moderation data labor (Kenyan data work)\n\t- Companies deliberately hire most vulnerable; prevents workers from speaking out\n\t- Moderation is a mental health concern\n- Milagros Miceli\n\t- Ultimately, QA abides by what client wants\n\t- Gig work is common; payment per task\n\t- Data work \u0026 content moderation outsourced\n- Safiya Umoja Noble\n\t- ‚ÄúConversations like this are how we become better advocates for each other‚Äù\n\t- We should be skeptical \u0026 careful\n\t- **Researchers should be taking a page out of climate scientists books: ‚Äúwish they had become activists, rather than just doing the research and handing it off to policy makers‚Äù**\n# AI Hype vs reality\n- Education (Belize Mont-Louis)\n\t- How to use technology intentionally so students benefit and are not harmed\n\t- Blocking or buying detector products not the right strategy, solution is better teaching\n\t- Designing educational strategies that evaluate students on factors LLMs\n\t- Rethink education that requires students to produce things that helps them learn what they need to\n\t- Improving public understanding of bias and limitations\n- Startups (Asmelash Teka)\n\t- GPT sucking up all the air in the room\n- Combatting hype (Mark Riedi)\n\t- tradeoff between precise vs understandable language / metaphor\n\t- LLMS as ‚Äúbackward looking‚Äù being applied to ‚Äúforward looking‚Äù problems\n- Productivity improvement\n\t- Utopian claims of AI companies\n\t- Counter to the incentive structure of capitalism: Automating a task is not rewarded with additional leisure time; labor structure just shifts\n\t- Shifting labor from creation to editing \u0026 oversight requires vigilance (humans are bad at this)\n- Education gaps for marginalized students\n\t- Who is the creator vs consumer of the technology?\n\t- Technology can often close gaps (increases access)\n\t- Mark: AI tech people have a choice in which area they want to disrupt. Often pick on teachers as inefficient or replaceable. The real problem is not how scale up / disrupt, it‚Äôs a resource allocation problem.\n\t- Teaching is not about information transfer, its about relationships and social development\n- Mark: nsf grant, promise first year we will write no code and just spend time interviewing and understanding teachers‚Äô needs and use cases\n- **Refreshing to hear that the first step for an AI researcher is to get to know and understand the stakeholders the tool is for / going to affect**\n- Mark: **‚ÄúYou can do good science without writing code‚Äù**\n- How to cut through the hype?\n\t- Stay focused on the things you care about\n\t- Use tools yourself. Try to break them. Figuring out what they can‚Äôt do identifies its boundaries \u0026 limitations\n\t- Counterpoint: every time you break and find a boundary, it provides the organization additional training data to extend the boundaries\n\t- Keep in mind what is being published as news may be marketing\n\t- Develop a strategy to identify good skeptical news outlets and journalists\n- Mark: last 4 months playing amateur sleuth ‚Äúglass onion GPT edition‚Äù (relatable üòÇüòÖ)\n# What‚Äôs next? A call to action\n- EU AI act (sarah andrew)\n\t- Small piece of legislation initially built under the assumption ‚ÄúAI‚Äù was just a new piece of tech; academics and NGOs jumped in and (successfully) expanded protections\n\t- Human rights protections built into creation and use\n\t- Use case specific legislation didn‚Äôt cover general purpose AI\n- Global south context (Nanjala Nyabola)\n\t- Gap in capacity to develop AI strategy \u0026 policy\n\t- Need international community to set baseline of conduct for disadvantaged nation states to protect themselves\n\t- Most elaborate misinformation campaigns run in disadvantaged nations (often by the state)\n\t- Unequal partnerships w/¬† lead to exploitative relationships\n\t- **‚ÄúConsequences of developing this technology will not be constrained by borders‚Äù**\n- Legal frameworks for Art and ownership (Steven Zapata)\n\t- Class action lawsuits against AI companies scoping what the problems are\n\t- Copyright infringement, fair use\n- Can the system be reimagined w/o exploitation?\n\t- Incentive distorting problems: 1. We exist to consume 2. Accumulation is good\n\t- The term ‚Äúethical‚Äù is slippery and nonspecific\n\t- **Ground the definition in human rights**\n- Amplify the stories of the harms occuring now. policy makers tend to fall into the thinking that AI conversations are only about the future\n- Demystify the rulemaking process (call for journalists and tech blogs) make sure information travels\n- Break down academic silos; have conversations and build diverse transdisciplinary coalitions.\n- **Purpose is not to win, the purpose to transform**\n- Need to educate representatives\n- ‚ÄúYou put out gpt4 and release it into the world, whatever bad things its capable of, its already capable of‚Äù red team examples:\n\t- Demonstrate its capacity to deceive a human on task rabbit to solve captchas\n\t- How can i make a deadly chemical with household ingredients?\n\t- That‚Äôs just what they decided to test; and then put guardrails in place to prevent those specific behaviors\n- Willful ignorance of tech industry\n- ‚ÄúWe‚Äôre either all going to make it, or none of us are going to make it‚Äù\n- Ask yourself: does the work that you‚Äôre doing help or harm?","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/thoughts/alignment":{"title":"Alignment","content":"üöß TODO üöß\n# Central themes\n- [[thoughts/participatory-design]]\n- [[thoughts/transparency]]\n- [[thoughts/biomimicry]]\n\n# Meaning Alignment\n- there are some interesting emerging ideas around [[notes/meaning|meaning]] aligned machine learning; I'm cautiously optimistic on this direction depending on what organizations ~~get involved~~ coopts the concept\n","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/thoughts/biomimicry":{"title":"Biomimicry","content":"\u003e*Biomimicry is basically taking a design challenge and then finding an ecosystem that's already solved that challenge, and literally trying to emulate what you learn.* --Janine Benyus\n- [Diverse Intelligences Summer Institute](https://disi.org/)\n- [Complex Intelligence: Natural, Artificial, and Collective](https://www.santafe.edu/research/themes/complex-intelligence-natural-artificial-and-collec)\n\ncopy form, process or mimicry at an ecosystems level\n\nobservation: in a software ecosystem, ai products will grow to exploit whatever niches we open for them","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/thoughts/ci":{"title":"Collective Intelligence","content":"[Collective Intelligence Project](https://cip.org/)\n# Ideas\n1. formal definitions of a bellman-esque objective embedded within a model of the entity or organization engaged in its development.\n2. [[cv/pubs/dac-rl|distributed consensus algorithms]] interoperable w/ human input. (decentralizing a meta policy by agents voting according to value function)\n3. Deliberative¬†democratic / [[thoughts/participatory-design|participatory design]] mechanisms (reading a lot of [Aviv Ovadya's](https://aviv.me/) recent work)\n4. Delegation of control between agents in a hybrid ai/human systems","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/thoughts/citizen-science":{"title":"citizen-science","content":"üöß TODO üöß \n\n# iNaturalist\nI'm always excited to find something new and curious I've never seen before, and adding new species to [my observations](https://www.inaturalist.org/observations?place_id=any\u0026user_id=mykewalton\u0026verifiable=any) recaptures the nostalgic magic of the Pok√©dex.\n","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/thoughts/democracy":{"title":"Democracy","content":"\n# Tools\n### Voting\n- [Pol.is](https://pol.is/)\n- [Loomio](https://www.loomio.com/)\n- [CommunityRule](https://communityrule.info/)\n- [QuadraticVote](https://quadraticvote.co/)\n\n### Deliberative Discourse\n- [Narwhal](https://www.thenarwhalproject.com/)","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/thoughts/digital-garden":{"title":"Digital Garden","content":"I was greatly inspired by Jacky Zhao's approach to [Networked Thought](https://jzhao.xyz/posts/networked-thought/) and decided to build my own garden using their excellent [Quartz](https://github.com/jackyzha0/quartz) project. Thanks Jacky! Check out some other awesome gardens built on Quartz [[notes/showcase|here]].\n\n# Building in the open\n\n\u003e *One who works with the door open gets all kinds of interruptions, but they also occasionally get clues as to what the world is and what might be important.* ‚Äî Richard Hamming","lastmodified":"2023-03-19T09:52:53.724371491Z","tags":null},"/thoughts/nomadism":{"title":"Nomadism","content":"\n[Transition Towns](https://transitionnetwork.org/): a movement I first read about in [[books/pluriverse|Designs for the Pluriverse]] \n\n# {Third, maker, hacker}spaces\n- [The Commons](https://www.thesfcommons.com/), SF\n- [Noisebridge](https://www.noisebridge.net/wiki/Noisebridge), SF\n- [Past Lives](https://www.pastlives.space/), PDX\n- [Hedron](https://hhacker.space/), PDX\n\n# Coliving Networks\nI'm followed with some passing interest development and discourse around [The Network States](https://thenetworkstate.com/)or various forms of coliving / cooperatives that blend virtual social spaces with physical environments. That said, I think there's a long way to go and you there's alot of (potential, mostly crypto) scams pioneering this space.\n- [Cabin](https://creators.mirror.xyz/)\n- [Kift](https://www.kift.com/)\n\n# Coliving search \u0026 temp accommodation\n- [Bungalow](https://bungalow.com/)\n- [Coliving](https://coliving.com/)\n\n# 'Traditional' coliving work exchange model\n- [WWOF](https://wwoofusa.org/en/)\n- [WorkAway](https://www.workaway.info/)\n- [helpx](https://www.helpx.net/)\n","lastmodified":"2023-03-19T09:52:53.732372099Z","tags":null},"/thoughts/participatory-design":{"title":"Participatory Design","content":"Participatory design (PD) is the active involvement of users in the design of some system, product or process. It is a [[thoughts/democracy|democratic]] approach to designing social and technological systems that involve  interaction with humans. PD approaches are premised on the belief that users ought to participate in the design of systems they will ultimately use. PD aims to ensure that all stakeholders, with a particular emphasis on end users, have equal opportunity to contribute to the systems' design.\n\nMany efforts have been made to incorporate user feedback and preferences in ML models (eg recommenders, RLHF: reinforcement learning from human feedback) however the application of *democratic* participation *at scale* to the entirety of the design process *end-to-end*, to my knowledge, has not been accomplished. It ~~should~~ needs to be.\n\n# Scaling Participatory AI\n- [[thoughts/citizen-science]]\n- [[thoughts/democracy]]\n- grassroots community building [[notes/microsolidarity]], [[books/emergent-strategy]]\n\n# Notes\n[PAIR 2020: Intentional ignorance is a value-laden choice](https://www.youtube.com/watch?v=TcE6_NPjvuo)\n- choice of dataset and curation define what is important\n- model selection encodes additional bias\n- generation of new data from users interacting with the model generates a bias feedback loop\n- over and underrepresentation of subpopulations encode value judgements\n- **foresight** is critical:\n\t- intended use / users\n\t- foreseeable use / users\n\t- foreseeable discriminatory uses\n\t- risks\n\t- foreseeable harms\n\t- foreseeable disproportionate harms\n- \"I'm just an engineer / data scientist\" is willful ignorance; inflicts foreseeable harm\n![[thoughts/images/bias_laundering.png]]\n\n\n","lastmodified":"2023-03-19T09:52:53.732372099Z","tags":null},"/thoughts/stewardship":{"title":"Stewardship","content":"In the physical world, there is a complex relationship between land *development* and land *stewardship*. Definitions vary (and often stewardship implys some form of development) but for our purposes we'll follow the wikipedia-level defintion and refer to *development* as 'changing landforms from a natural or semi-natural state for a purpose, such as agriculture or housing'. \n\nStewardship, however is more nuanced. Its definition is context-dependent but the unifying theme is *caring* for a piece of land, regardless of its ownership. Caring about all the biodiverse species that belong to the land; its people, their culture and their customs.\n\nSimilarly, in the virtual world, the language technologists use to describe the roles we play and the methods we use are a reflection of our values. Today, the art and science of creating software artifacts is carried out primarily under the title *[developer](https://www.youtube.com/watch?v=Vhh_GeBPOhs\u0026ab_channel=MrWueb007)*.\n\nContrary to commonly incentivised strategies of unfettered growth, development and disruption; what might it look like to _care_ for health of the planetary cyberphysical system our technologies shape? For all our progress, are the diverse beings that people the internet healthy? happy? thriving?\n\nBelow are some thoughts on how we might evolve into better *stewards* of our shared virtual ecosystem.\n\n# The Dark Forest\n\n![[thoughts/images/cozyweb-1800.jpg|700]]*Illustration from Maggie Appleton's [AI Dark Forest](https://maggieappleton.com/ai-dark-forest)*\n","lastmodified":"2023-03-19T09:52:53.732372099Z","tags":null},"/thoughts/transparency":{"title":"Transparancy","content":"\n- [Data Cards Playbook](https://sites.research.google/datacardsplaybook/)\n- [Reward Reports](https://rewardreports.github.io/)\n- [AIAAIC](https://www.aiaaic.org/home)\n- ","lastmodified":"2023-03-19T09:52:53.732372099Z","tags":null},"/thoughts/web3":{"title":"web3","content":"\n- [web3 is going great](https://web3isgoinggreat.com/)\n- [My first impressions of web3](https://moxie.org/2022/01/07/web3-first-impressions.html), Moxie Marlinspike\n- [Virtual Violence](https://www.kernelmag.io/2/virtual-violence), Kadallah Burrowes\n- ","lastmodified":"2023-03-19T09:52:53.732372099Z","tags":null}}